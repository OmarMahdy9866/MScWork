{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.696873200Z",
     "start_time": "2023-10-20T19:35:41.635134100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.0+cpu'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing PyTorch\n",
    "import torch\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading training & testing dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbb36ee516ca7af6"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "   H   B   q  R_int  gamma  Su  sf_lower  sf_upper\n0  8   4  10    0.6     18  25     1.041     1.087\n1  8   4  10    0.8     18  25     1.044     1.087\n2  6  20  20    0.8     18  25     1.045     1.080\n3  6  20  20    0.6     18  25     1.047     1.080\n4  6  20  20    1.0     18  25     1.048     1.080",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>H</th>\n      <th>B</th>\n      <th>q</th>\n      <th>R_int</th>\n      <th>gamma</th>\n      <th>Su</th>\n      <th>sf_lower</th>\n      <th>sf_upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0.6</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.041</td>\n      <td>1.087</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.044</td>\n      <td>1.087</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.8</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.045</td>\n      <td>1.080</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.6</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.047</td>\n      <td>1.080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>1.0</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.048</td>\n      <td>1.080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  # Import the Pandas library for data manipulation.\n",
    "\n",
    "# Define the input file name as a variable for easy modification.\n",
    "input_file = 'output_results.csv'\n",
    "\n",
    "# Read the CSV data from the specified input file into a Pandas DataFrame.\n",
    "csv_data = pd.read_csv(input_file)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data.\n",
    "csv_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.714790700Z",
     "start_time": "2023-10-20T19:35:41.639806400Z"
    }
   },
   "id": "d00bccb29d8a987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining MyDataset class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2738b7bb2241051"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Class definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dccbbfe0a5e1d45"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch dataset for loading data from a CSV file and preparing it for training or testing.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The path to the CSV file containing the dataset.\n",
    "        train_test_ratio (float, optional): The ratio of the dataset to be used for training (default is 0.9).\n",
    "        test (bool, optional): If True, the dataset is prepared for testing; otherwise, it's prepared for training (default is False).\n",
    "\n",
    "    Attributes:\n",
    "        x_data (torch.Tensor): The input data.\n",
    "        y_data (torch.Tensor): The target data.\n",
    "\n",
    "    Methods:\n",
    "        __len__(): Returns the number of samples in the dataset.\n",
    "        __getitem__(idx): Returns the input and target data for a specific index.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_name, train_test_ratio=0.95, test=False):\n",
    "        \"\"\"\n",
    "        Initializes the MyDataset with data from a CSV file.\n",
    "\n",
    "        Args:\n",
    "            file_name (str): The path to the CSV file containing the dataset.\n",
    "            train_test_ratio (float, optional): The ratio of the dataset to be used for training (default is 0.9).\n",
    "            test (bool, optional): If True, the dataset is prepared for testing; otherwise, it's prepared for training (default is False).\n",
    "        \"\"\"\n",
    "        _df = pd.read_csv(file_name)\n",
    "\n",
    "        if test:\n",
    "            data_len = math.floor((1 - train_test_ratio) * len(_df.iloc[:, 0]))\n",
    "        else:\n",
    "            data_len = math.floor(train_test_ratio * len(_df.iloc[:, 0]))\n",
    "\n",
    "        x = _df.iloc[:data_len, :-2].values\n",
    "        y = _df.iloc[:data_len, -2:].values\n",
    "\n",
    "        self.x_data = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.y_data)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.729793400Z",
     "start_time": "2023-10-20T19:35:41.647142800Z"
    }
   },
   "id": "7464ea69ecd596bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. MyDataset class implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c962857e018270b"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Create a training dataset from the input CSV file.\n",
    "train_dataset = MyDataset(input_file)\n",
    "\n",
    "# Create a testing dataset from the input CSV file.\n",
    "test_dataset = MyDataset(input_file, test=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.801809600Z",
     "start_time": "2023-10-20T19:35:41.653875900Z"
    }
   },
   "id": "c5000dbf6d77f99c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters:**\n",
    "\n",
    "- Number of training epochs: `EPOCH = 10`\n",
    "- Batch size for mini-batch gradient descent: `BATCH_SIZE = 10`\n",
    "- Learning rate for the optimization algorithm (e.g., stochastic gradient descent): `LR = 0.001`\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26cf6d81c9cc0f55"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - PyTorch uses random numbers in various operations, such as weight initialization, data shuffling, and more.\n",
    "# - By setting the random seed to a specific value (in this case, 1), we ensure that the same random numbers are generated every time we run the code.\n",
    "# - This is important for reproducibility, which means getting the same results each time you run the code.\n",
    "# - Reproducibility is crucial in machine learning and deep learning to validate and compare results.\n",
    "\n",
    "# Note: Setting the random seed to 1 is just an example. You can choose any integer value for reproducibility.\n",
    "torch.manual_seed(1)  # Reproducible\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCH = 10\n",
    "\n",
    "# Batch size for mini-batch gradient descent\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Learning rate for the optimization algorithm (e.g., stochastic gradient descent)\n",
    "LR = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.814812600Z",
     "start_time": "2023-10-20T19:35:41.662750400Z"
    }
   },
   "id": "afac10a2dc4547b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Loaders and Batch Information:**\n",
    "\n",
    "- Import the necessary DataLoader module from PyTorch to handle dataset loading.\n",
    "\n",
    "- Create a data loader for the training dataset with the following parameters:\n",
    "  - Batch size: `BATCH_SIZE`\n",
    "  - No shuffle.\n",
    "\n",
    "- Create a data loader for the test dataset with the same parameters as the training data loader.\n",
    "\n",
    "- To obtain a single batch of training data and labels, use the `next` function on an iterator created from `train_loader`.\n",
    "\n",
    "- Display the shape of the feature batch:\n",
    "  - `train_features.size()` returns the shape (dimensions) of the feature batch.\n",
    "\n",
    "- Display the shape of the label batch:\n",
    "  - `train_labels.size()` returns the shape (dimensions) of the label batch.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d818ed21eab4807"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 6])\n",
      "Labels batch shape: torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a data loader for the training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create a data loader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Obtain a single batch of training data and labels using the `train_loader`.\n",
    "# This is done by using the `next` function on an iterator created from `train_loader`.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "# Print the shape of the feature batch.\n",
    "# `train_features.size()` returns the shape (dimensions) of the feature batch.\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "\n",
    "# Print the shape of the label batch.\n",
    "# `train_labels.size()` returns the shape (dimensions) of the label batch.\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.818813500Z",
     "start_time": "2023-10-20T19:35:41.669713900Z"
    }
   },
   "id": "7ff0d3a2eadf153b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple Linear Regression Neural Network\n",
    "\n",
    "Defines a PyTorch neural network module for multiple linear regression. The neural network consists of three fully connected layers, and the docstring provides a detailed explanation of its structure and usage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c824695773fbba"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(CNN, self)._init_()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(32*6, 2)  # 32 is the number of output channels, 6 is the sequence length\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:35:41.832816800Z",
     "start_time": "2023-10-20T19:35:41.673373800Z"
    }
   },
   "id": "5df4548818a46476"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the Multiple Linear Regression (MLR) Model\n",
    "\n",
    "An instance of the Multiple Linear Regression (MLR) model is created and its parameters are printed. The MLR model is designed for regression tasks, and in this instance, it is configured with 6 input features and is expected to produce 2 output values.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bcf6998ef19e73"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  []\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the MultipleLinearRegression model with 6 input features and 2 output units.\n",
    "MLR_model = CNN()\n",
    "\n",
    "# Print the parameters of the MLR model.\n",
    "print(\"The parameters: \", list(MLR_model.parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:37:16.442985300Z",
     "start_time": "2023-10-20T19:37:16.435527800Z"
    }
   },
   "id": "655857979ef2f3ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Optimization and Loss Definition\n",
    "\n",
    "In this section, the model optimizer is selected, and the loss criterion for training the Multiple Linear Regression model is defined.\n",
    "\n",
    "## Model Optimizer\n",
    "We use the AdamW optimizer to update the model parameters during training. The learning rate (LR) determines the step size for parameter updates."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9260b10bfb223ff5"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdamW\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMLR_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLR\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\optim\\adamw.py:52\u001B[0m, in \u001B[0;36mAdamW.__init__\u001B[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weight_decay value: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweight_decay\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     40\u001B[0m defaults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m     41\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m     42\u001B[0m     betas\u001B[38;5;241m=\u001B[39mbetas,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     50\u001B[0m     fused\u001B[38;5;241m=\u001B[39mfused,\n\u001B[0;32m     51\u001B[0m )\n\u001B[1;32m---> 52\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:261\u001B[0m, in \u001B[0;36mOptimizer.__init__\u001B[1;34m(self, params, defaults)\u001B[0m\n\u001B[0;32m    259\u001B[0m param_groups \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(params)\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(param_groups) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer got an empty parameter list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(param_groups[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    263\u001B[0m     param_groups \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: param_groups}]\n",
      "\u001B[1;31mValueError\u001B[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(MLR_model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:37:25.209296300Z",
     "start_time": "2023-10-20T19:37:25.179569800Z"
    }
   },
   "id": "14dae56105a05687"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the Mean Squared Error (MSE) loss criterion\n",
    "criterion = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.710790Z"
    }
   },
   "id": "48c1cfc3a08776fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Prediction Check (Before Training)\n",
    "\n",
    "In this section, we check the model's ability to make predictions before any training has occurred. This is often referred to as a \"sanity check\" to ensure the model is functional.\n",
    "\n",
    "## Model Prediction\n",
    "We provide a sample input tensor `x` to the Multiple Linear Regression (MLR) model and evaluate its prediction. Please note that at this stage, the model has not undergone any training.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "564034c92c2bb88b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the model gives data (NO TRAINING YET)\n",
    "x = torch.tensor([[8, 6, 10, 1.0, 16, 100]])\n",
    "x = x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "y_pred = MLR_model(x)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.712789800Z"
    }
   },
   "id": "809ad0813ed69a1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training Loop\n",
    "\n",
    "In this section, we define the training loop for the Multiple Linear Regression (MLR) model. The training process involves multiple epochs, where the model learns from the training data to optimize its parameters and reduce the loss."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8855654381dd7061"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_losses = []\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = MLR_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        t_losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Print training statistics\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{EPOCH}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.714790700Z"
    }
   },
   "id": "44f33a3d2911e3ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation on Test Data\n",
    "\n",
    "In this section, we evaluate the trained MLR model on the test dataset and calculate the test loss to assess the model's performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a460d7d9d2ade25e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Iterate over batches in the test loader\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = MLR_model(inputs)  # Forward pass to get model predictions\n",
    "        loss = criterion(outputs, targets)  # Calculate the loss\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate the loss for all batches\n",
    "    \n",
    "    mean_loss = total_loss / len(test_loader)  # Calculate the mean loss over all batches\n",
    "    print(f'Test Loss: {mean_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.715791100Z"
    }
   },
   "id": "529056adbdc3cb28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Training Losses\n",
    "\n",
    "In this section, we visualize the training progress by plotting the training losses. The loss values are plotted against the number of iterations, providing insight into the model's convergence during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aecccf978b37a589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(t_losses)\n",
    "plt.xlabel(\"No. of Iterations\")\n",
    "plt.ylabel(\"Total Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.716790300Z"
    }
   },
   "id": "77e25dc5823a50df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the Model\n",
    "\n",
    "In this section, we evaluate the trained model by testing it on a set of case histories. The case histories include parameters and known outcomes for different locations.\n",
    "\n",
    "## Case Histories Parameters\n",
    "We define a list of case histories parameters, where each sub-list represents a location's specific parameters:\n",
    "\n",
    "```python\n",
    "cases = [\n",
    "    [2.4, 4.8, 15, 1, 19, 12],   # Fornebu, Oslo\n",
    "    [5, 5, 0, 1, 19, 16],       # Feria, Oslo\n",
    "    [11.3, 16, 0, 1, 19, 35]    # Chicago, USA\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88ea3ab88445cb6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "# Case histories parameters\n",
    "# Input is on the form [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "\n",
    "cases = [\n",
    "    [2.4, 4.8, 15, 1, 19, 12],  # Fornebu, Oslo\n",
    "    [5, 5, 0, 1, 19, 16],      # Feria, Oslo\n",
    "    [11.3, 16, 0, 1, 19, 35]   # Chicago, USA\n",
    "]\n",
    "\n",
    "\n",
    "# Case histories outcomes\n",
    "cases_op = [\n",
    "    [1.03, 1.11, 0.97, 1.05],  # Fornebu, Oslo\n",
    "    [1.02, 1.26, 1.03, 1.1],  # Feria, Oslo\n",
    "    [1, 1.11, 0.95, 1]        # Chicago, USA\n",
    "]\n",
    "\n",
    "for i, each_case in enumerate(cases):\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))\n",
    "    val = float(np.average(y_pred_MLR.detach()))\n",
    "    cases_op[i].append(val)\n",
    "    print(f'Avg. FoS for case_{i} is {val}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.718790900Z"
    }
   },
   "id": "79f485e3d16d0486"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "species = ('Fornebu, Oslo', 'Feria, Oslo', 'Chicago, USA')\n",
    "\n",
    "means = {\n",
    "    \"Eide's (1956)\": [],\n",
    "    \"Terzaghi (1943)\": [],\n",
    "    \"Simplified UBLA\": [],\n",
    "    \"Modified Terzaghi\": [],\n",
    "    \"FELA-FNN\": []\n",
    "}\n",
    "\n",
    "# Assuming you have 'cases_op' defined elsewhere\n",
    "\n",
    "for i, items in enumerate(means.items()):\n",
    "    means[items[0]] += ([x[i] for x in cases_op])\n",
    "\n",
    "x = np.arange(len(species))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.4, 5.5))\n",
    "\n",
    "for attribute, measurement in means.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('FoS')\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0.5,1.5)\n",
    "\n",
    "# Adjust the x-axis tick positions and labels\n",
    "new_x = x + width * (len(means) - 1) / 2\n",
    "ax.set_xticks(new_x)\n",
    "ax.set_xticklabels(species, rotation=0, ha='center', fontsize=8, fontweight='bold')  # Adjust 'ha' to 'center'\n",
    "\n",
    "# Adjust the legend location to 'upper right' and specify the number of columns (ncols)\n",
    "legend = ax.legend(loc='upper right', ncols=1)\n",
    "\n",
    "# Set the transparency of the legend background to 50%\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "\n",
    "ax.axhline(y=1, color='red', linestyle='--', label='Y = 1')\n",
    "\n",
    "# Set the chart title with a customizable font size\n",
    "chart_title = \"Comparison between the FoS predictions of different classical approaches and the FELA-FNN\"\n",
    "title_fontsize = 8  # You can adjust the font size as needed\n",
    "ax.set_title(chart_title, fontsize=title_fontsize, fontweight='bold')  # Make the title bold\n",
    "\n",
    "# Increase figure quality by adjusting the DPI\n",
    "plt.savefig('your_figure_600_2.png', dpi=600)  # You can adjust the filename and DPI as needed\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.719791300Z"
    }
   },
   "id": "7efee78296036e22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Su vs. FoS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfd2521e2dbcf56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' \n",
    "    B:      Excavation width (m)\n",
    "    H:      Excavation height (m)\n",
    "    q:      Uniform surcharge at GS (kPa)\n",
    "    Rint:   Interface strength reduction factor\n",
    "    Gamma:  Soil unit weight (kN/cu.m)\n",
    "    Su:     Undrained shear strength (kPa)\n",
    "    \n",
    "case_input = [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "y_pred_MLR = MLR_model(torch.Tensor(each_case))\n",
    "LB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "UB_FoS = float(np.max(y_pred_MLR.detach()))\n",
    "\n",
    "'''\n",
    "no_of_curve_points = 50\n",
    "B = 5\n",
    "H = 10\n",
    "q = 20\n",
    "Rint = 1\n",
    "Gamma = 19\n",
    "su = range(0, no_of_curve_points, 1)  # Changed the step size to 1\n",
    "\n",
    "cases = []\n",
    "for i in su:\n",
    "    cases.append([B, H, q, Rint, Gamma, i])\n",
    "\n",
    "for each_case in cases:\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))    \n",
    "    LB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "    print('LB FoS: ', LB_FoS)\n",
    "    UB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "    print('UB FoS: ',UB_FoS)\n",
    "    Avg_FoS = float(np.average(y_pred_MLR.detach()))\n",
    "    print(Avg_FoS)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.720791300Z"
    }
   },
   "id": "947e449f652c01ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#cases\n",
    "print('Nahh')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.721791300Z"
    }
   },
   "id": "abe438dbf0995847"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' \n",
    "    B:      Excavation width (m)\n",
    "    H:      Excavation height (m)\n",
    "    q:      Uniform surcharge at GS (kPa)\n",
    "    Rint:   Interface strength reduction factor\n",
    "    Gamma:  Soil unit weight (kN/cu.m)\n",
    "    Su:     Undrained shear strength (kPa)\n",
    "    \n",
    "case_input = [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "'''\n",
    "\n",
    "no_of_curve_points = 50\n",
    "B = 5\n",
    "H = 10\n",
    "q = 20\n",
    "Rint = 1\n",
    "Gamma = 19\n",
    "su = range(0, no_of_curve_points, 1)  # Changed the step size to 1\n",
    "\n",
    "cases = []\n",
    "for i in su:\n",
    "    cases.append([B, H, q, Rint, Gamma, i])\n",
    "\n",
    "for each_case in cases:\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))    \n",
    "    print(float(min(y_pred_MLR.detach())))\n",
    "    Avg_FoS = float(np.average(y_pred_MLR.detach()))\n",
    "    print('Avg FoS: ', Avg_FoS)  # Print the average factor of safety"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.722791600Z"
    }
   },
   "id": "a007754b206a1883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:35:41.723792Z"
    }
   },
   "id": "ddfc08335a36031d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
