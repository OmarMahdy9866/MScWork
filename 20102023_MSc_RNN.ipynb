{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:57.843401400Z",
     "start_time": "2023-10-20T19:38:56.224023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.0+cpu'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing PyTorch\n",
    "import torch\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading training & testing dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbb36ee516ca7af6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   H   B   q  R_int  gamma  Su  sf_lower  sf_upper\n0  8   4  10    0.6     18  25     1.041     1.087\n1  8   4  10    0.8     18  25     1.044     1.087\n2  6  20  20    0.8     18  25     1.045     1.080\n3  6  20  20    0.6     18  25     1.047     1.080\n4  6  20  20    1.0     18  25     1.048     1.080",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>H</th>\n      <th>B</th>\n      <th>q</th>\n      <th>R_int</th>\n      <th>gamma</th>\n      <th>Su</th>\n      <th>sf_lower</th>\n      <th>sf_upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0.6</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.041</td>\n      <td>1.087</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0.8</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.044</td>\n      <td>1.087</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.8</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.045</td>\n      <td>1.080</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>0.6</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.047</td>\n      <td>1.080</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>20</td>\n      <td>20</td>\n      <td>1.0</td>\n      <td>18</td>\n      <td>25</td>\n      <td>1.048</td>\n      <td>1.080</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  # Import the Pandas library for data manipulation.\n",
    "\n",
    "# Define the input file name as a variable for easy modification.\n",
    "input_file = 'output_results.csv'\n",
    "\n",
    "# Read the CSV data from the specified input file into a Pandas DataFrame.\n",
    "csv_data = pd.read_csv(input_file)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data.\n",
    "csv_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.124756900Z",
     "start_time": "2023-10-20T19:38:57.844402200Z"
    }
   },
   "id": "d00bccb29d8a987e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining MyDataset class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2738b7bb2241051"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Class definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dccbbfe0a5e1d45"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch dataset for loading data from a CSV file and preparing it for training or testing.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The path to the CSV file containing the dataset.\n",
    "        train_test_ratio (float, optional): The ratio of the dataset to be used for training (default is 0.9).\n",
    "        test (bool, optional): If True, the dataset is prepared for testing; otherwise, it's prepared for training (default is False).\n",
    "\n",
    "    Attributes:\n",
    "        x_data (torch.Tensor): The input data.\n",
    "        y_data (torch.Tensor): The target data.\n",
    "\n",
    "    Methods:\n",
    "        __len__(): Returns the number of samples in the dataset.\n",
    "        __getitem__(idx): Returns the input and target data for a specific index.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_name, train_test_ratio=0.95, test=False):\n",
    "        \"\"\"\n",
    "        Initializes the MyDataset with data from a CSV file.\n",
    "\n",
    "        Args:\n",
    "            file_name (str): The path to the CSV file containing the dataset.\n",
    "            train_test_ratio (float, optional): The ratio of the dataset to be used for training (default is 0.9).\n",
    "            test (bool, optional): If True, the dataset is prepared for testing; otherwise, it's prepared for training (default is False).\n",
    "        \"\"\"\n",
    "        _df = pd.read_csv(file_name)\n",
    "\n",
    "        if test:\n",
    "            data_len = math.floor((1 - train_test_ratio) * len(_df.iloc[:, 0]))\n",
    "        else:\n",
    "            data_len = math.floor(train_test_ratio * len(_df.iloc[:, 0]))\n",
    "\n",
    "        x = _df.iloc[:data_len, :-2].values\n",
    "        y = _df.iloc[:data_len, -2:].values\n",
    "\n",
    "        self.x_data = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.y_data)[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.124756900Z",
     "start_time": "2023-10-20T19:38:58.118193Z"
    }
   },
   "id": "7464ea69ecd596bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. MyDataset class implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c962857e018270b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Create a training dataset from the input CSV file.\n",
    "train_dataset = MyDataset(input_file)\n",
    "\n",
    "# Create a testing dataset from the input CSV file.\n",
    "test_dataset = MyDataset(input_file, test=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.137420300Z",
     "start_time": "2023-10-20T19:38:58.123756700Z"
    }
   },
   "id": "c5000dbf6d77f99c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hyperparameters:**\n",
    "\n",
    "- Number of training epochs: `EPOCH = 10`\n",
    "- Batch size for mini-batch gradient descent: `BATCH_SIZE = 10`\n",
    "- Learning rate for the optimization algorithm (e.g., stochastic gradient descent): `LR = 0.001`\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26cf6d81c9cc0f55"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# - PyTorch uses random numbers in various operations, such as weight initialization, data shuffling, and more.\n",
    "# - By setting the random seed to a specific value (in this case, 1), we ensure that the same random numbers are generated every time we run the code.\n",
    "# - This is important for reproducibility, which means getting the same results each time you run the code.\n",
    "# - Reproducibility is crucial in machine learning and deep learning to validate and compare results.\n",
    "\n",
    "# Note: Setting the random seed to 1 is just an example. You can choose any integer value for reproducibility.\n",
    "torch.manual_seed(1)  # Reproducible\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCH = 10\n",
    "\n",
    "# Batch size for mini-batch gradient descent\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Learning rate for the optimization algorithm (e.g., stochastic gradient descent)\n",
    "LR = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.165112200Z",
     "start_time": "2023-10-20T19:38:58.133419300Z"
    }
   },
   "id": "afac10a2dc4547b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Loaders and Batch Information:**\n",
    "\n",
    "- Import the necessary DataLoader module from PyTorch to handle dataset loading.\n",
    "\n",
    "- Create a data loader for the training dataset with the following parameters:\n",
    "  - Batch size: `BATCH_SIZE`\n",
    "  - No shuffle.\n",
    "\n",
    "- Create a data loader for the test dataset with the same parameters as the training data loader.\n",
    "\n",
    "- To obtain a single batch of training data and labels, use the `next` function on an iterator created from `train_loader`.\n",
    "\n",
    "- Display the shape of the feature batch:\n",
    "  - `train_features.size()` returns the shape (dimensions) of the feature batch.\n",
    "\n",
    "- Display the shape of the label batch:\n",
    "  - `train_labels.size()` returns the shape (dimensions) of the label batch.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d818ed21eab4807"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([10, 6])\n",
      "Labels batch shape: torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a data loader for the training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create a data loader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Obtain a single batch of training data and labels using the `train_loader`.\n",
    "# This is done by using the `next` function on an iterator created from `train_loader`.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "# Print the shape of the feature batch.\n",
    "# `train_features.size()` returns the shape (dimensions) of the feature batch.\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "\n",
    "# Print the shape of the label batch.\n",
    "# `train_labels.size()` returns the shape (dimensions) of the label batch.\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.186116800Z",
     "start_time": "2023-10-20T19:38:58.138420Z"
    }
   },
   "id": "7ff0d3a2eadf153b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple Linear Regression Neural Network\n",
    "\n",
    "Defines a PyTorch neural network module for multiple linear regression. The neural network consists of three fully connected layers, and the docstring provides a detailed explanation of its structure and usage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62c824695773fbba"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=6, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.187119700Z",
     "start_time": "2023-10-20T19:38:58.148221500Z"
    }
   },
   "id": "5df4548818a46476"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the Multiple Linear Regression (MLR) Model\n",
    "\n",
    "An instance of the Multiple Linear Regression (MLR) model is created and its parameters are printed. The MLR model is designed for regression tasks, and in this instance, it is configured with 6 input features and is expected to produce 2 output values.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bcf6998ef19e73"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  [Parameter containing:\n",
      "tensor([[-0.0343,  0.0830, -0.1664,  0.1060, -0.0364,  0.0899],\n",
      "        [ 0.0246, -0.0216,  0.0490,  0.0087,  0.0646, -0.0689],\n",
      "        [-0.0129, -0.0159,  0.0256, -0.0007,  0.1545,  0.0550],\n",
      "        [-0.0658, -0.1068, -0.0296, -0.0763, -0.0566,  0.0085],\n",
      "        [ 0.1054,  0.0961, -0.1728,  0.1096,  0.0494,  0.1677],\n",
      "        [ 0.1167, -0.1611, -0.1681, -0.0853,  0.1552, -0.0294],\n",
      "        [ 0.0757, -0.0822,  0.1735, -0.0748,  0.1326,  0.0021],\n",
      "        [-0.0931,  0.0909, -0.0938,  0.0520, -0.0510, -0.0194],\n",
      "        [-0.1700, -0.0843,  0.0959, -0.0430,  0.1761,  0.1417],\n",
      "        [-0.0083, -0.1180,  0.1077,  0.0549, -0.1143,  0.1148],\n",
      "        [ 0.1073,  0.1568, -0.0991, -0.0291, -0.0034,  0.0258],\n",
      "        [-0.1342, -0.1254,  0.0962, -0.0415,  0.0864,  0.0101],\n",
      "        [ 0.0580,  0.0389,  0.0643,  0.0876, -0.1637,  0.0890],\n",
      "        [-0.1243, -0.1334,  0.0108, -0.0301,  0.1038, -0.1024],\n",
      "        [-0.1572,  0.1287, -0.0262,  0.0994,  0.0568, -0.1326],\n",
      "        [ 0.0355,  0.0425, -0.1184, -0.0839,  0.0603,  0.0317],\n",
      "        [-0.0752, -0.0535,  0.1619, -0.0327,  0.0997,  0.0765],\n",
      "        [-0.1143, -0.1503,  0.1697,  0.0092,  0.1212,  0.0366],\n",
      "        [ 0.0569,  0.1320,  0.1676, -0.1173,  0.0221,  0.1319],\n",
      "        [ 0.1281,  0.1098, -0.1279, -0.1273, -0.1069,  0.0222],\n",
      "        [ 0.1762, -0.1117,  0.0942, -0.0978, -0.1662, -0.0376],\n",
      "        [ 0.1019,  0.1641, -0.1098,  0.0384,  0.1525,  0.1171],\n",
      "        [ 0.1102,  0.1256,  0.1118,  0.0457, -0.1209, -0.1484],\n",
      "        [-0.0810, -0.0206, -0.1084,  0.0647,  0.0547, -0.0400],\n",
      "        [ 0.0679,  0.0571,  0.1079,  0.1190, -0.0599,  0.1727],\n",
      "        [-0.0204, -0.0061, -0.1669, -0.1138, -0.1033, -0.0756],\n",
      "        [ 0.1257, -0.0578, -0.1321,  0.0680,  0.0566,  0.1145],\n",
      "        [-0.0915,  0.0383, -0.0644, -0.0397, -0.1409, -0.0806],\n",
      "        [-0.0541,  0.0756,  0.0323,  0.0437,  0.1764,  0.1723],\n",
      "        [ 0.1206,  0.0056, -0.1223,  0.1382, -0.0442, -0.0143],\n",
      "        [-0.1523, -0.0349, -0.1140,  0.1624, -0.1528, -0.1378],\n",
      "        [-0.0060, -0.0956,  0.0633, -0.0680, -0.0830,  0.0100]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1280, -0.1243,  0.0830,  ..., -0.1245,  0.0864, -0.1270],\n",
      "        [-0.0405,  0.1286,  0.1400,  ..., -0.0885,  0.1020,  0.1087],\n",
      "        [-0.0102, -0.0218,  0.1606,  ...,  0.1487, -0.0335,  0.0357],\n",
      "        ...,\n",
      "        [ 0.1361,  0.0558, -0.0505,  ...,  0.0194, -0.1150, -0.0962],\n",
      "        [-0.0015, -0.0932,  0.1636,  ...,  0.0730,  0.0301,  0.0887],\n",
      "        [ 0.0628,  0.0863,  0.1106,  ...,  0.1018,  0.1614, -0.0699]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0787, -0.1434, -0.0218, -0.1124, -0.0337,  0.1006,  0.0881, -0.0930,\n",
      "        -0.0438, -0.0354, -0.0673, -0.0968,  0.1298,  0.1222,  0.1476, -0.0971,\n",
      "         0.1295, -0.0536, -0.0415, -0.0476, -0.0086, -0.0774,  0.0242, -0.1139,\n",
      "         0.0727, -0.1482, -0.0641, -0.1235,  0.1192,  0.1215, -0.1406, -0.0965],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1582,  0.0515,  0.1217, -0.1355,  0.0798,  0.1125, -0.0410, -0.0081,\n",
      "         0.1289,  0.0482,  0.0507,  0.0005, -0.0738, -0.1082,  0.1764, -0.0140,\n",
      "         0.1569,  0.1446, -0.0924,  0.0120, -0.0452, -0.0032,  0.1165,  0.0973,\n",
      "        -0.1004, -0.0875, -0.1256, -0.1501,  0.1134, -0.1092,  0.0023, -0.0002],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0302, -0.0103,  0.0917,  0.0243,  0.1268,  0.0382, -0.0022,  0.0250,\n",
      "          0.1178,  0.0267,  0.1245, -0.0168,  0.0015,  0.1485, -0.1669,  0.0176,\n",
      "          0.1615, -0.0887, -0.0326, -0.0107,  0.0582,  0.0668,  0.0400,  0.0697,\n",
      "         -0.0758,  0.0744, -0.0561,  0.1111, -0.0519, -0.1505,  0.0126,  0.0920],\n",
      "        [-0.0069,  0.0023,  0.0006,  0.0938,  0.0138, -0.1579, -0.1261,  0.0104,\n",
      "         -0.0142,  0.1690, -0.0416,  0.1353, -0.1491, -0.1680, -0.0163, -0.1119,\n",
      "         -0.0516,  0.0199, -0.1533,  0.1215, -0.1073,  0.1356,  0.0578, -0.0332,\n",
      "         -0.1547,  0.0293, -0.0988,  0.1528, -0.1487, -0.0467, -0.0974, -0.1137]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0922, -0.0175], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the MultipleLinearRegression model with 6 input features and 2 output units.\n",
    "MLR_model = RNN()\n",
    "\n",
    "# Print the parameters of the MLR model.\n",
    "print(\"The parameters: \", list(MLR_model.parameters()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.207121600Z",
     "start_time": "2023-10-20T19:38:58.151605600Z"
    }
   },
   "id": "655857979ef2f3ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Optimization and Loss Definition\n",
    "\n",
    "In this section, the model optimizer is selected, and the loss criterion for training the Multiple Linear Regression model is defined.\n",
    "\n",
    "## Model Optimizer\n",
    "We use the AdamW optimizer to update the model parameters during training. The learning rate (LR) determines the step size for parameter updates."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9260b10bfb223ff5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(MLR_model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.421944Z",
     "start_time": "2023-10-20T19:38:58.162111600Z"
    }
   },
   "id": "14dae56105a05687"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Define the Mean Squared Error (MSE) loss criterion\n",
    "criterion = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:58.436066Z",
     "start_time": "2023-10-20T19:38:58.422944200Z"
    }
   },
   "id": "48c1cfc3a08776fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Prediction Check (Before Training)\n",
    "\n",
    "In this section, we check the model's ability to make predictions before any training has occurred. This is often referred to as a \"sanity check\" to ensure the model is functional.\n",
    "\n",
    "## Model Prediction\n",
    "We provide a sample input tensor `x` to the Multiple Linear Regression (MLR) model and evaluate its prediction. Please note that at this stage, the model has not undergone any training.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "564034c92c2bb88b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "RNN: Expected input to be 2D or 3D, got 1D tensor instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Check the model gives data (NO TRAINING YET)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m100\u001B[39m])\n\u001B[1;32m----> 3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mMLR_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_pred)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 11\u001B[0m, in \u001B[0;36mRNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 11\u001B[0m     out, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :])\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MScWork\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:522\u001B[0m, in \u001B[0;36mRNN.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    520\u001B[0m batch_sizes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m--> 522\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRNN: Expected input to be 2D or 3D, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mD tensor instead\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    523\u001B[0m is_batched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m    524\u001B[0m batch_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: RNN: Expected input to be 2D or 3D, got 1D tensor instead"
     ]
    }
   ],
   "source": [
    "# Check the model gives data (NO TRAINING YET)\n",
    "x = torch.tensor([8, 6, 10, 1.0, 16, 100])\n",
    "y_pred = MLR_model(x)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:59.090116600Z",
     "start_time": "2023-10-20T19:38:58.426063300Z"
    }
   },
   "id": "809ad0813ed69a1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training Loop\n",
    "\n",
    "In this section, we define the training loop for the Multiple Linear Regression (MLR) model. The training process involves multiple epochs, where the model learns from the training data to optimize its parameters and reduce the loss."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8855654381dd7061"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_losses = []\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = MLR_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        t_losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Print training statistics\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{EPOCH}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.089116900Z"
    }
   },
   "id": "44f33a3d2911e3ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation on Test Data\n",
    "\n",
    "In this section, we evaluate the trained MLR model on the test dataset and calculate the test loss to assess the model's performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a460d7d9d2ade25e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Iterate over batches in the test loader\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = MLR_model(inputs)  # Forward pass to get model predictions\n",
    "        loss = criterion(outputs, targets)  # Calculate the loss\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate the loss for all batches\n",
    "    \n",
    "    mean_loss = total_loss / len(test_loader)  # Calculate the mean loss over all batches\n",
    "    print(f'Test Loss: {mean_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:59.093117300Z",
     "start_time": "2023-10-20T19:38:59.092116700Z"
    }
   },
   "id": "529056adbdc3cb28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Training Losses\n",
    "\n",
    "In this section, we visualize the training progress by plotting the training losses. The loss values are plotted against the number of iterations, providing insight into the model's convergence during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aecccf978b37a589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(t_losses)\n",
    "plt.xlabel(\"No. of Iterations\")\n",
    "plt.ylabel(\"Total Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.094117600Z"
    }
   },
   "id": "77e25dc5823a50df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing the Model\n",
    "\n",
    "In this section, we evaluate the trained model by testing it on a set of case histories. The case histories include parameters and known outcomes for different locations.\n",
    "\n",
    "## Case Histories Parameters\n",
    "We define a list of case histories parameters, where each sub-list represents a location's specific parameters:\n",
    "\n",
    "```python\n",
    "cases = [\n",
    "    [2.4, 4.8, 15, 1, 19, 12],   # Fornebu, Oslo\n",
    "    [5, 5, 0, 1, 19, 16],       # Feria, Oslo\n",
    "    [11.3, 16, 0, 1, 19, 35]    # Chicago, USA\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88ea3ab88445cb6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "\n",
    "# Case histories parameters\n",
    "# Input is on the form [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "\n",
    "cases = [\n",
    "    [2.4, 4.8, 15, 1, 19, 12],  # Fornebu, Oslo\n",
    "    [5, 5, 0, 1, 19, 16],      # Feria, Oslo\n",
    "    [11.3, 16, 0, 1, 19, 35]   # Chicago, USA\n",
    "]\n",
    "\n",
    "\n",
    "# Case histories outcomes\n",
    "cases_op = [\n",
    "    [1.03, 1.11, 0.97, 1.05],  # Fornebu, Oslo\n",
    "    [1.02, 1.26, 1.03, 1.1],  # Feria, Oslo\n",
    "    [1, 1.11, 0.95, 1]        # Chicago, USA\n",
    "]\n",
    "\n",
    "for i, each_case in enumerate(cases):\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))\n",
    "    val = float(np.average(y_pred_MLR.detach()))\n",
    "    cases_op[i].append(val)\n",
    "    print(f'Avg. FoS for case_{i} is {val}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.096118Z"
    }
   },
   "id": "79f485e3d16d0486"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "species = ('Fornebu, Oslo', 'Feria, Oslo', 'Chicago, USA')\n",
    "\n",
    "means = {\n",
    "    \"Eide's (1956)\": [],\n",
    "    \"Terzaghi (1943)\": [],\n",
    "    \"Simplified UBLA\": [],\n",
    "    \"Modified Terzaghi\": [],\n",
    "    \"FELA-FNN\": []\n",
    "}\n",
    "\n",
    "# Assuming you have 'cases_op' defined elsewhere\n",
    "\n",
    "for i, items in enumerate(means.items()):\n",
    "    means[items[0]] += ([x[i] for x in cases_op])\n",
    "\n",
    "x = np.arange(len(species))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.4, 5.5))\n",
    "\n",
    "for attribute, measurement in means.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('FoS')\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0.5,1.5)\n",
    "\n",
    "# Adjust the x-axis tick positions and labels\n",
    "new_x = x + width * (len(means) - 1) / 2\n",
    "ax.set_xticks(new_x)\n",
    "ax.set_xticklabels(species, rotation=0, ha='center', fontsize=8, fontweight='bold')  # Adjust 'ha' to 'center'\n",
    "\n",
    "# Adjust the legend location to 'upper right' and specify the number of columns (ncols)\n",
    "legend = ax.legend(loc='upper right', ncols=1)\n",
    "\n",
    "# Set the transparency of the legend background to 50%\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "\n",
    "ax.axhline(y=1, color='red', linestyle='--', label='Y = 1')\n",
    "\n",
    "# Set the chart title with a customizable font size\n",
    "chart_title = \"Comparison between the FoS predictions of different classical approaches and the FELA-FNN\"\n",
    "title_fontsize = 8  # You can adjust the font size as needed\n",
    "ax.set_title(chart_title, fontsize=title_fontsize, fontweight='bold')  # Make the title bold\n",
    "\n",
    "# Increase figure quality by adjusting the DPI\n",
    "plt.savefig('your_figure_600_2.png', dpi=600)  # You can adjust the filename and DPI as needed\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T19:38:59.110121200Z",
     "start_time": "2023-10-20T19:38:59.098118400Z"
    }
   },
   "id": "7efee78296036e22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Su vs. FoS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfd2521e2dbcf56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' \n",
    "    B:      Excavation width (m)\n",
    "    H:      Excavation height (m)\n",
    "    q:      Uniform surcharge at GS (kPa)\n",
    "    Rint:   Interface strength reduction factor\n",
    "    Gamma:  Soil unit weight (kN/cu.m)\n",
    "    Su:     Undrained shear strength (kPa)\n",
    "    \n",
    "case_input = [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "y_pred_MLR = MLR_model(torch.Tensor(each_case))\n",
    "LB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "UB_FoS = float(np.max(y_pred_MLR.detach()))\n",
    "\n",
    "'''\n",
    "no_of_curve_points = 50\n",
    "B = 5\n",
    "H = 10\n",
    "q = 20\n",
    "Rint = 1\n",
    "Gamma = 19\n",
    "su = range(0, no_of_curve_points, 1)  # Changed the step size to 1\n",
    "\n",
    "cases = []\n",
    "for i in su:\n",
    "    cases.append([B, H, q, Rint, Gamma, i])\n",
    "\n",
    "for each_case in cases:\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))    \n",
    "    LB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "    print('LB FoS: ', LB_FoS)\n",
    "    UB_FoS = float(np.min(y_pred_MLR.detach()))\n",
    "    print('UB FoS: ',UB_FoS)\n",
    "    Avg_FoS = float(np.average(y_pred_MLR.detach()))\n",
    "    print(Avg_FoS)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.100118900Z"
    }
   },
   "id": "947e449f652c01ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#cases\n",
    "print('Nahh')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.101119Z"
    }
   },
   "id": "abe438dbf0995847"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' \n",
    "    B:      Excavation width (m)\n",
    "    H:      Excavation height (m)\n",
    "    q:      Uniform surcharge at GS (kPa)\n",
    "    Rint:   Interface strength reduction factor\n",
    "    Gamma:  Soil unit weight (kN/cu.m)\n",
    "    Su:     Undrained shear strength (kPa)\n",
    "    \n",
    "case_input = [B (m), H (m), q (kPa), Rint, Gamma (kN/cu.m), Su (kPa)]\n",
    "'''\n",
    "\n",
    "no_of_curve_points = 50\n",
    "B = 5\n",
    "H = 10\n",
    "q = 20\n",
    "Rint = 1\n",
    "Gamma = 19\n",
    "su = range(0, no_of_curve_points, 1)  # Changed the step size to 1\n",
    "\n",
    "cases = []\n",
    "for i in su:\n",
    "    cases.append([B, H, q, Rint, Gamma, i])\n",
    "\n",
    "for each_case in cases:\n",
    "    y_pred_MLR = MLR_model(torch.Tensor(each_case))    \n",
    "    print(float(min(y_pred_MLR.detach())))\n",
    "    Avg_FoS = float(np.average(y_pred_MLR.detach()))\n",
    "    print('Avg FoS: ', Avg_FoS)  # Print the average factor of safety"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.102119700Z"
    }
   },
   "id": "a007754b206a1883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-20T19:38:59.104119700Z"
    }
   },
   "id": "ddfc08335a36031d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
